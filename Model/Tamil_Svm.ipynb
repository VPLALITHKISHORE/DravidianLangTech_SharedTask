{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gCprnaLK8L1",
        "outputId": "c965ac64-2044-41dc-df15-945b699a7b65"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lj-bPWatLdpa"
      },
      "outputs": [],
      "source": [
        "stopwords_english = set(stopwords.words('english'))\n",
        "stopwords_tamil = set(['அங்கு', 'அங்கே', 'அடுத்த', 'அதனால்', 'அதன்', 'அதற்கு', 'அதிக', 'அதில்', 'அது', 'அதே', 'அதை', 'அந்த', 'அந்தக்', 'அந்தப்', 'அன்று', 'அல்லது', 'அவன்', 'அவரது', 'அவர்', 'அவர்கள்', 'அவள்', 'அவை', 'ஆகிய', 'ஆகியோர்', 'ஆகும்', 'இங்கு', 'இங்கே', 'இடத்தில்', 'இடம்', 'இதனால்', 'இதனை', 'இதன்', 'இதற்கு', 'இதில்', 'இது', 'இதை', 'இந்த', 'இந்தக்', 'இந்தத்', 'இந்தப்', 'இன்னும்', 'இப்போது', 'இரு', 'இருக்கும்', 'இருந்த', 'இருந்தது', 'இருந்து', 'இவர்', 'இவை', 'உன்', 'உள்ள', 'உள்ளது', 'உள்ளன', 'எந்த', 'என', 'எனக்', 'எனக்கு', 'எனப்படும்', 'எனவும்', 'எனவே', 'எனினும்', 'எனும்', 'என்', 'என்ன', 'என்னும்', 'என்பது', 'என்பதை', 'என்ற', 'என்று', 'என்றும்', 'எல்லாம்', 'ஏன்', 'ஒரு', 'ஒரே', 'ஓர்', 'கொண்ட', 'கொண்டு', 'கொள்ள', 'சற்று', 'சிறு', 'சில', 'சேர்ந்த', 'தனது', 'தன்', 'தவிர', 'தான்', 'நான்', 'நாம்', 'நீ', 'பற்றி', 'பற்றிய', 'பல', 'பலரும்', 'பல்வேறு', 'பின்', 'பின்னர்', 'பிற', 'பிறகு', 'பெரும்', 'பேர்', 'போது', 'போன்ற', 'போல', 'போல்', 'மட்டுமே', 'மட்டும்', 'மற்ற', 'மற்றும்', 'மிக', 'மிகவும்', 'மீது', 'முதல்', 'முறை', 'மேலும்', 'மேல்', 'யார்', 'வந்த', 'வந்து', 'வரும்', 'வரை', 'வரையில்', 'விட', 'விட்டு', 'வேண்டும்', 'வேறு'])\n",
        "stopwords_combined = stopwords_english.union(stopwords_tamil)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDWi5P9gLiJu"
      },
      "outputs": [],
      "source": [
        "# Preprocessing function for Tanglish\n",
        "def preprocess_tanglish(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s\\u0B80-\\u0BFF]', '', text)\n",
        "    text_tokens = text.split()\n",
        "    text_tokens = [word for word in text_tokens if word not in stopwords_combined]\n",
        "\n",
        "\n",
        "    return ' '.join(text_tokens)\n",
        "\n",
        "# Load datasets\n",
        "df_train = pd.read_csv(\"/content/Tam-SA-train.csv\")\n",
        "df_valid = pd.read_csv(\"/content/Tam-SA-val.csv\")\n",
        "df_test = pd.read_csv(\"/content/Tam-SA-test-without-labels.csv\")\n",
        "\n",
        "# Apply preprocessing\n",
        "df_train['Text'] = df_train['Text'].apply(preprocess_tanglish)\n",
        "df_valid['Text'] = df_valid['Text'].apply(preprocess_tanglish)\n",
        "df_test['Text'] = df_test['Text'].apply(preprocess_tanglish)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqQOrGTLL4bI"
      },
      "outputs": [],
      "source": [
        "# Step 1: Feature Extraction using TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train = vectorizer.fit_transform(df_train['Text'])\n",
        "X_valid = vectorizer.transform(df_valid['Text'])\n",
        "X_test = vectorizer.transform(df_test['Text'])\n",
        "\n",
        "# Step 2: Prepare target labels for training and validation\n",
        "y_train = df_train['Label']\n",
        "y_valid = df_valid['Label']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EJLpjORL62-"
      },
      "outputs": [],
      "source": [
        "# Step 3: Initialize SVM classifier\n",
        "svm_classifier = SVC(kernel='linear', C=1, class_weight='balanced')\n",
        "\n",
        "# Step 4: Train the model using the training data\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Validate the model using the validation data\n",
        "y_valid_pred = svm_classifier.predict(X_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOSB62IhL-gd",
        "outputId": "b0dded42-116b-49cc-c83a-a65118067a76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6325787145459276\n",
            "Validation Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Mixed_feelings       0.23      0.04      0.07       472\n",
            "      Negative       0.52      0.30      0.38       480\n",
            "      Positive       0.67      0.91      0.77      2272\n",
            " unknown_state       0.48      0.33      0.39       619\n",
            "\n",
            "      accuracy                           0.63      3843\n",
            "     macro avg       0.48      0.40      0.40      3843\n",
            "  weighted avg       0.57      0.63      0.58      3843\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on validation data\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_valid, y_valid_pred))\n",
        "print(\"Validation Classification Report:\")\n",
        "print(classification_report(y_valid, y_valid_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVRkvtvsMkQ_",
        "outputId": "d3bd990b-0d2e-49f2-fc4a-65fb0d1fdbea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         Id                                               Text Predicted_Label\n",
            "0  SA_Ta_01  thalaivan oruvane thalapathy matume mass thala...        Positive\n",
            "1  SA_Ta_02  kandipaga tamilnadu arasiyal kizhikaraa padam ...        Positive\n",
            "2  SA_Ta_03  ajith actinghaha vijay actinghahahahaaha hahah...        Positive\n",
            "3  SA_Ta_04  உண்மையா லவ் பண்ணி வீட்ல சம்மதிக்கலனா பண்ண பொண்...  Mixed_feelings\n",
            "4  SA_Ta_05  chiiiiiii mokka punda trailer wigpathy sura 2 ...        Negative\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Test the model using the test data (No labels in test data)\n",
        "y_test_pred = svm_classifier.predict(X_test)\n",
        "df_test['Predicted_Label'] = y_test_pred\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "df_test.to_csv('tamil_test_predictions_svm.csv', index=False)\n",
        "\n",
        "# Optionally, print a few predictions\n",
        "print(df_test[['Id', 'Text', 'Predicted_Label']].head())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
