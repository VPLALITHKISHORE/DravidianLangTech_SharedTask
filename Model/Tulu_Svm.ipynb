{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xH4sPTOhz-qO",
        "outputId": "ee286129-4f38-4751-807b-edb87c8533f0"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "Best Parameters: {'C': 10, 'kernel': 'rbf'}\n",
            "Validation Accuracy: 0.6114494518879415\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Mixed       0.28      0.17      0.22       143\n",
            "    Negative       0.25      0.26      0.26       118\n",
            "     Neutral       0.55      0.60      0.57       368\n",
            "    Not Tulu       0.73      0.77      0.75       543\n",
            "    Positive       0.68      0.66      0.67       470\n",
            "\n",
            "    accuracy                           0.61      1642\n",
            "   macro avg       0.50      0.49      0.49      1642\n",
            "weighted avg       0.60      0.61      0.61      1642\n",
            "\n",
            "Validation AUC-ROC Score: 0.462704276067869\n",
            "         Id                                      Original_Text Predicted_Label\n",
            "0  SA_TU_01              Keep it up bro...... always pukuliü§£ü§£ü§£        Not Tulu\n",
            "1  SA_TU_02  Nxt comedy film geppanaga umben seravarle iyav...        Not Tulu\n",
            "2  SA_TU_03  How Nepal is connected with Mangalore. Music h...        Not Tulu\n",
            "3  SA_TU_04    papa mare imbena maya athna pukulin vapas korad         Neutral\n",
            "4  SA_TU_05  ‡≤§‡≥Å‡≤≤‡≥Å ‡≤™‡≥Å‡≤∞‡≥ç‡≤™‡≤ó‡≥ç ‡≤¨‡≤§‡≥ç‡≤§‡≥ç‡≤Ç‡≤°‡≥ç ‡≤Ö‡≤∏‡≥ç‡≤∏‡≤æ‡≤Ç‚Äå‡≤¶ ‡≤Æ‡≥Å‡≤ñ‡≥ç‡≤Ø‡≤Æ‡≤Ç‡≤§‡≥ç‡≤∞‡≤ø‡≤≤‡≥Ü‡≤® ...         Neutral\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Define Tulu stopwords (example list; replace with actual Tulu stopwords)\n",
        "stopwords_tulu = set(['‡≤Ö‡≤µ‡≤∞‡≥Å', '‡≤á‡≤¶‡≥Å', '‡≤Ü‡≤ó', '‡≤®‡≤æ‡≤®‡≥Å', '‡≤Ö‡≤≤‡≥ç‡≤≤‡≤ø', '‡≤Ö‡≤¶‡≤®‡≥ç‡≤®‡≥Å', '‡≤é‡≤Ç‡≤¶‡≥Ü‡≤∞‡≥Ü', '‡≤Ö‡≤¶‡≥á', '‡≤Ö‡≤Ç‡≤§‡≤æ', '‡≤Ö‡≤¶‡≥Å', '‡≤Æ‡≤§‡≥ç‡≤§‡≥Å'])\n",
        "\n",
        "# Combine English and Tulu stopwords\n",
        "stopwords_english = set(stopwords.words('english'))\n",
        "stopwords_combined = stopwords_english.union(stopwords_tulu)\n",
        "\n",
        "# Preprocessing function for Tulu text\n",
        "def preprocess_tulu(text):\n",
        "    if pd.isnull(text):\n",
        "        return \"\"\n",
        "\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\u0C80-\\u0CFF\\s]', '', text)\n",
        "    text_tokens = text.split()\n",
        "    text_tokens = [word for word in text_tokens if word not in stopwords_combined]\n",
        "\n",
        "    return ' '.join(text_tokens)\n",
        "\n",
        "# Load datasets\n",
        "df_train = pd.read_csv(\"/content/Tulu_SA_train.csv\")\n",
        "df_valid = pd.read_csv(\"/content/Tulu_SA_val.csv\")\n",
        "df_test = pd.read_csv(\"/content/Tulu_SA_test_without_label.csv\")\n",
        "\n",
        "\n",
        "df_test['Original_Text'] = df_test['Text']\n",
        "\n",
        "# Preprocessing step for all datasets\n",
        "df_train['Text'] = df_train['Text'].apply(preprocess_tulu)\n",
        "df_valid['Text'] = df_valid['Text'].apply(preprocess_tulu)\n",
        "df_test['Text'] = df_test['Text'].apply(preprocess_tulu)\n",
        "\n",
        "\n",
        "df_train['Text'] = df_train['Text'].replace('', 'empty_text')\n",
        "df_valid['Text'] = df_valid['Text'].replace('', 'empty_text')\n",
        "df_test['Text'] = df_test['Text'].replace('', 'empty_text')\n",
        "\n",
        "# Ensure no NaN in labels\n",
        "df_train.dropna(subset=['Label'], inplace=True)\n",
        "df_valid.dropna(subset=['Label'], inplace=True)\n",
        "\n",
        "# Step 1: Feature Extraction using TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), min_df=3)\n",
        "X_train = vectorizer.fit_transform(df_train['Text'])\n",
        "X_valid = vectorizer.transform(df_valid['Text'])\n",
        "X_test = vectorizer.transform(df_test['Text'])\n",
        "\n",
        "# Step 2: Prepare target labels for training and validation\n",
        "y_train = df_train['Label']\n",
        "y_valid = df_valid['Label']\n",
        "\n",
        "# Step 3: Handle Class Imbalance with SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Step 4: Hyperparameter Tuning using GridSearchCV\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf']\n",
        "}\n",
        "svm = SVC(class_weight='balanced', probability=True)\n",
        "grid_search = GridSearchCV(svm, param_grid, scoring='f1_weighted', cv=3, verbose=1)\n",
        "grid_search.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "best_svm = grid_search.best_estimator_\n",
        "\n",
        "# Step 5: Validate the model using the validation data\n",
        "y_valid_pred = best_svm.predict(X_valid)\n",
        "\n",
        "# Evaluate the model on validation data\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_valid, y_valid_pred))\n",
        "print(\"Validation Classification Report:\")\n",
        "print(classification_report(y_valid, y_valid_pred))\n",
        "\n",
        "# Calculate AUC-ROC for each class (One-vs-Rest strategy)\n",
        "y_valid_binarized = label_binarize(y_valid, classes=df_train['Label'].unique())\n",
        "y_valid_pred_prob = best_svm.predict_proba(X_valid)\n",
        "roc_auc = roc_auc_score(y_valid_binarized, y_valid_pred_prob, average='macro', multi_class='ovr')\n",
        "print(\"Validation AUC-ROC Score:\", roc_auc)\n",
        "\n",
        "# Step 6: Test the model using the test data (No labels in test data)\n",
        "y_test_pred = best_svm.predict(X_test)\n",
        "\n",
        "# Add the predictions to the test dataframe\n",
        "df_test['Predicted_Label'] = y_test_pred\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "df_test[['Id', 'Original_Text', 'Predicted_Label']].to_csv('tulu_test_predictions_svm2.csv', index=False)\n",
        "\n",
        "# Optionally, print a few predictions\n",
        "print(df_test[['Id', 'Original_Text', 'Predicted_Label']].head())\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}